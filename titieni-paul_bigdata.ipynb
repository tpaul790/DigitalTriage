{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Home = Low Severity. The patient was stable enough to recover on their own.\n",
    "\n",
    "Home With Service Facility: = Medium Severity. The patient was stable, but still needed a nurse or therapist to visit them.\n",
    "\n",
    "Extended Care Facility: = High Severity. The patient was not stable enough to go home and needed 24/7 care in a skilled nursing or rehab facility.\n",
    "\n",
    "Expired = Critical Severity. The patient's condition was fatal.\n",
    "\n",
    "..."
   ],
   "id": "acb7f846583d73d3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T11:31:44.120687Z",
     "start_time": "2025-11-12T11:31:44.105610Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# Hugging Face and Transformers\n",
    "try:\n",
    "    from datasets import Dataset, DatasetDict, load_from_disk\n",
    "    from transformers import (\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSequenceClassification,\n",
    "        TrainingArguments,\n",
    "        Trainer,\n",
    "        EarlyStoppingCallback,\n",
    "        pipeline\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"ImportError: Hugging Face libraries not found.\")\n",
    "    print(\"Please run: pip install torch transformers datasets scikit-learn pandas numpy matplotlib seaborn accelerate\")\n",
    "    exit()\n",
    "\n",
    "# SKLearn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CONFIGURATION",
   "id": "6443c14d355a0f2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:17:55.185106Z",
     "start_time": "2025-11-11T17:17:55.183230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data files\n",
    "TRAIN_FILE = \"data/bigdata/train.csv\"\n",
    "VAL_FILE = \"data/bigdata/val.csv\"\n",
    "TEST_FILE = \"data/bigdata/test.csv\"\n",
    "\n",
    "# Lighter data settings\n",
    "\n",
    "N_TRAIN_ROWS = 5000  \n",
    "N_TEST_ROWS = 500    \n",
    "\n",
    "# Preprocessing\n",
    "TARGET_COLUMN = 'discharge_disposition'\n",
    "\n",
    "# Using ClinicalBERT for its domain-specific knowledge\n",
    "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "MAX_TOKEN_LENGTH = 512\n",
    "PROCESSED_DATA_DIR = \"data/processed_data/tpaul/processed_triage_data\"\n",
    "LABEL_INFO_FILE = \"data/info/tpaul/label_info.json\"\n",
    "\n",
    "# Training\n",
    "MODEL_OUTPUT_DIR = \"models/tpaul/triage_classifier_model\"\n",
    "\n",
    "# --- Lighter training settings ---\n",
    "BATCH_SIZE = 2 \n",
    "\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "# Evaluation\n",
    "CONFUSION_MATRIX_FILE = \"evaluation/tpaul/confusion_matrix.png\""
   ],
   "id": "26cf5ab62435e3ef",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PREPROCESSING",
   "id": "a17cb303841e9bca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:17:55.237543Z",
     "start_time": "2025-11-11T17:17:55.232086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_label_maps() -> Dict[str, Any]:\n",
    "    print(\"Creating complete label mappings from a sample of data...\")\n",
    "    try:\n",
    "        df_train = pd.read_csv(TRAIN_FILE, usecols=[TARGET_COLUMN], nrows=N_TRAIN_ROWS)\n",
    "        df_val = pd.read_csv(VAL_FILE, usecols=[TARGET_COLUMN], nrows=N_TEST_ROWS)\n",
    "        df_test = pd.read_csv(TEST_FILE, usecols=[TARGET_COLUMN], nrows=N_TEST_ROWS)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Make sure {TRAIN_FILE}, {VAL_FILE}, and {TEST_FILE} exist.\")\n",
    "        df_train = []\n",
    "        df_val = []\n",
    "        df_test = []\n",
    "\n",
    "    all_labels = pd.concat([df_train, df_val, df_test])\n",
    "    all_labels[TARGET_COLUMN] = all_labels[TARGET_COLUMN].fillna('Unknown').astype(str).str.strip()\n",
    "\n",
    "    unique_labels = all_labels[TARGET_COLUMN].unique()\n",
    "    unique_labels.sort()\n",
    "\n",
    "    # Create mappings\n",
    "    label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    num_labels = len(unique_labels)\n",
    "\n",
    "    print(f\"Found {num_labels} unique labels in the sample.\")\n",
    "\n",
    "    label_info = {'label2id': label2id, 'id2label': id2label, 'num_labels': num_labels}\n",
    "\n",
    "    # Ensure parent directories exist before saving\n",
    "    os.makedirs(os.path.dirname(LABEL_INFO_FILE) or '.', exist_ok=True)\n",
    "    \n",
    "    # Save mappings to disk\n",
    "    with open(LABEL_INFO_FILE, 'w') as f:\n",
    "        json.dump(label_info, f)\n",
    "\n",
    "    return label_info\n",
    "\n",
    "def preprocess(label2id: Dict[str, int]):\n",
    "    print(\"\\n--- STARTING PREPROCESSING ---\")\n",
    "\n",
    "    # Load Data\n",
    "    print(f\"Loading datasets (Train: {N_TRAIN_ROWS} rows, Val/Test: {N_TEST_ROWS} rows)...\")\n",
    "    try:\n",
    "        df_train = pd.read_csv(TRAIN_FILE, nrows=N_TRAIN_ROWS)\n",
    "        df_val = pd.read_csv(VAL_FILE, nrows=N_TEST_ROWS)\n",
    "        df_test = pd.read_csv(TEST_FILE, nrows=N_TEST_ROWS)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(f\"Please ensure {TRAIN_FILE}, {VAL_FILE}, and {TEST_FILE} are in the correct paths.\")\n",
    "        df_train = []\n",
    "        df_val = []\n",
    "        df_test = []\n",
    "        print(\"Warning: Created dummy data to proceed.\")\n",
    "\n",
    "    print(f\"Train shape: {df_train.shape}, Val shape: {df_val.shape}, Test shape: {df_test.shape}\")\n",
    "\n",
    "    print(f\"Loading tokenizer: {MODEL_NAME}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def preprocess_function(examples: Dict[str, List[Any]]) -> Dict[str, Any]:\n",
    "        cc_list = [str(cc) if cc is not None and pd.notna(cc) else \"\" for cc in examples[\"chief_complaint\"]]\n",
    "        hpi_list = [str(hpi) if hpi is not None and pd.notna(hpi) else \"\" for hpi in examples[\"history_of_present_illness\"]]\n",
    "\n",
    "        text = [f\"CHIEF COMPLAINT: {cc} | HISTORY: {hpi}\" for cc, hpi in zip(cc_list, hpi_list)]\n",
    "\n",
    "        tokenized_inputs = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_TOKEN_LENGTH\n",
    "        )\n",
    "\n",
    "        if TARGET_COLUMN in examples:\n",
    "            cleaned_labels = [str(label).strip() if label is not None and pd.notna(label) else 'Unknown' for label in examples[TARGET_COLUMN]]\n",
    "            tokenized_inputs[\"labels\"] = [label2id.get(label, label2id['Unknown']) for label in cleaned_labels]\n",
    "\n",
    "        return tokenized_inputs\n",
    "\n",
    "    # Convert Pandas to Hugging Face Datasets\n",
    "    print(\"Converting Pandas DataFrames to Hugging Face Datasets...\")\n",
    "    ds_train = Dataset.from_pandas(df_train)\n",
    "    ds_val = Dataset.from_pandas(df_val)\n",
    "    ds_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "    print(\"Tokenizing datasets...\")\n",
    "    tokenized_train = ds_train.map(preprocess_function, batched=True)\n",
    "    tokenized_val = ds_val.map(preprocess_function, batched=True)\n",
    "    tokenized_test = ds_test.map(preprocess_function, batched=True)\n",
    "\n",
    "    # Create the final DatasetDict\n",
    "    processed_dataset = DatasetDict({\n",
    "        'train': tokenized_train,\n",
    "        'validation': tokenized_val,\n",
    "        'test': tokenized_test\n",
    "    })\n",
    "    print(\"\\nTokenization complete. Processed dataset:\")\n",
    "    print(processed_dataset)\n",
    "\n",
    "    # Save Processed Data\n",
    "    print(f\"Saving processed dataset to disk at {PROCESSED_DATA_DIR}...\")\n",
    "    if os.path.exists(PROCESSED_DATA_DIR):\n",
    "        print(f\"Removing old processed data at {PROCESSED_DATA_DIR}\")\n",
    "        shutil.rmtree(PROCESSED_DATA_DIR)\n",
    "    processed_dataset.save_to_disk(PROCESSED_DATA_DIR)\n",
    "\n",
    "    print(\"--- PREPROCESSING COMPLETE ---\")\n"
   ],
   "id": "46e87dbf58bf164e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MODEL FINE-TUNING",
   "id": "dab1af413ceb8ff4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:17:55.275678Z",
     "start_time": "2025-11-11T17:17:55.269868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred: Tuple[np.ndarray, np.ndarray]) -> Dict[str, float]:\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
    "    precision = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1,\n",
    "        'precision_weighted': precision,\n",
    "        'recall_weighted': recall\n",
    "    }\n",
    "\n",
    "def finetune(label_info: Dict[str, Any], device: torch.device):\n",
    "    \"\"\"\n",
    "    Loads the processed data, fine-tunes the ClinicalBERT model,\n",
    "    and saves the best model.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- STARTING MODEL FINE-TUNING ---\")\n",
    "\n",
    "    # Load Processed Data\n",
    "    try:\n",
    "        print(f\"Loading processed dataset from {PROCESSED_DATA_DIR}...\")\n",
    "        processed_dataset = load_from_disk(PROCESSED_DATA_DIR)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Processed data not found at {PROCESSED_DATA_DIR}.\")\n",
    "        return\n",
    "\n",
    "    # Load Pre-trained Model\n",
    "    print(f\"Loading pre-trained model: {MODEL_NAME}...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=label_info['num_labels'],\n",
    "        label2id=label_info['label2id'],\n",
    "        id2label=label_info['id2label']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Defining training arguments...\")\n",
    "    os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=MODEL_OUTPUT_DIR,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE, \n",
    "        per_device_eval_batch_size=BATCH_SIZE, \n",
    "        gradient_accumulation_steps=4, \n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,      \n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\"              \n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_dataset['train'],\n",
    "        eval_dataset=processed_dataset['validation'],\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate and Save\n",
    "    print(\"Evaluating best model on validation set...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(json.dumps(eval_results, indent=2))\n",
    "\n",
    "    print(f\"Saving final model to {MODEL_OUTPUT_DIR}\")\n",
    "    trainer.save_model(MODEL_OUTPUT_DIR)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.save_pretrained(MODEL_OUTPUT_DIR)\n",
    "\n",
    "    print(\"--- FINE-TUNNING COMPLETE ---\")"
   ],
   "id": "980f915f4f6004c6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EVALUATION ",
   "id": "31587fc742d917cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:17:57.867141Z",
     "start_time": "2025-11-11T17:17:57.858511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_and_infer(label_info: Dict[str, Any], device: torch.device):\n",
    "    print(\"\\n--- STARTING EVALUATION & INFERENCE ---\")\n",
    "\n",
    "    print(f\"Loading fine-tuned model from {MODEL_OUTPUT_DIR}...\")\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_OUTPUT_DIR)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_OUTPUT_DIR)\n",
    "        model.to(device)\n",
    "    except OSError:\n",
    "        print(f\"Error: Model not found at {MODEL_OUTPUT_DIR}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading processed test data from {PROCESSED_DATA_DIR}...\")\n",
    "    try:\n",
    "        processed_dataset = load_from_disk(PROCESSED_DATA_DIR)\n",
    "        test_dataset = processed_dataset['test']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Processed data not found at {PROCESSED_DATA_DIR}.\")\n",
    "        return\n",
    "\n",
    "    id2label = {int(k): v for k, v in label_info['id2label'].items()}\n",
    "\n",
    "    all_label_indices = list(range(label_info['num_labels']))\n",
    "    all_label_names = [id2label.get(i, f\"UNK_{i}\") for i in all_label_indices] \n",
    "\n",
    "    print(\"Running predictions on the test set...\")\n",
    "    os.makedirs(\"./temp_eval\", exist_ok=True)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(output_dir=\"./temp_eval\", per_device_eval_batch_size=BATCH_SIZE)\n",
    "    )\n",
    "\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "    y_true = predictions.label_ids\n",
    "\n",
    "    print(\"\\n--- Test Set Classification Report ---\")\n",
    "\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=all_label_indices, \n",
    "        target_names=all_label_names,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    print(report)\n",
    "\n",
    "    print(\"Generating confusion matrix...\")\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=all_label_indices)\n",
    "\n",
    "    figsize_x = max(10, label_info['num_labels'])\n",
    "    figsize_y = max(8, label_info['num_labels'])\n",
    "\n",
    "    plt.figure(figsize=(figsize_x, figsize_y))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=all_label_names, yticklabels=all_label_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix for Triage Prediction (Test Set)')\n",
    "    plt.tight_layout() \n",
    "\n",
    "    os.makedirs(os.path.dirname(CONFUSION_MATRIX_FILE) or '.', exist_ok=True)\n",
    "    plt.savefig(CONFUSION_MATRIX_FILE)\n",
    "    print(f\"Confusion matrix saved to {CONFUSION_MATRIX_FILE}\")\n",
    "\n",
    "    print(\"\\n--- Running Sample Inference ---\")\n",
    "\n",
    "    triage_pipe = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=0 if (device.type == \"cuda\") else -1 \n",
    "    )\n",
    "\n",
    "    # Test with a new patient\n",
    "    new_chief_complaint = \"Patient presents with chest pain and difficulty breathing.\"\n",
    "    new_history = \"73-year-old male with a history of hypertension and diabetes. Smoker for 30 years.\"\n",
    "\n",
    "    input_text = f\"CHIEF COMPLAINT: {new_chief_complaint} | HISTORY: {new_history}\"\n",
    "\n",
    "    print(f\"\\nInput Text:\\n{input_text}\")\n",
    "\n",
    "    prediction = triage_pipe(input_text)\n",
    "    print(\"\\n--- Prediction ---\")\n",
    "    print(json.dumps(prediction, indent=2))\n",
    "\n",
    "    all_scores = triage_pipe(input_text, return_all_scores=True)\n",
    "    print(\"\\n--- All scores ---\")\n",
    "    all_scores_sorted = sorted(all_scores[0], key=lambda x: x['score'], reverse=True)\n",
    "    print(json.dumps(all_scores_sorted, indent=2))\n",
    "\n",
    "    print(\"--- EVALUATION COMPLETE ---\")\n"
   ],
   "id": "ca88c1d4a66257d2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MAIN EXECUTION",
   "id": "3d7ffb9d24a4efe7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Runs the full pipeline:\n",
    "    1. Preprocess data\n",
    "    2. Fine-tune model\n",
    "    3. Evaluate and infer\n",
    "    \"\"\"\n",
    "    print(\"====== STARTING TRIAGE MODEL ======\")\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    try:\n",
    "        label_info = get_label_maps()\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal Error during label map creation: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        preprocess(label_info['label2id'])\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal Error during Preprocessing: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        finetune(label_info, device)\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal Error during Fine-tuning: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        evaluate_and_infer(label_info, device)\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal Error during Evaluation: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"====== TRIAGE MODEL COMPLETE ======\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "c124e019a44f9bb0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
